{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining Prompts and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries and env variables\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AzureOpenAI\n",
    "from typing import Optional\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=os.getenv(\"OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data models for each stage\n",
    "class EventExtraction(BaseModel):\n",
    "    \"\"\"First LLM call: Extract basic event information\"\"\"\n",
    "\n",
    "    description: str = Field(description=\"Raw description of the event\")\n",
    "    is_calendar_event: bool = Field(description=\"Whether this text describes a calendar event\")\n",
    "    confidence_score: float = Field(description=\"Confidence score between 0 and 1\")\n",
    "\n",
    "\n",
    "class EventDetails(BaseModel):\n",
    "    \"\"\"Second LLM call: Parse specific event details\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the event\")\n",
    "    date: str = Field(description=\"Date and time of the event. Use ISO 8601 to format this value.\")\n",
    "    duration_minutes: int = Field(description=\"Expected duration in minutes\")\n",
    "    participants: list[str] = Field(description=\"List of participants\")\n",
    "\n",
    "\n",
    "class EventConfirmation(BaseModel):\n",
    "    \"\"\"Third LLM call: Generate confirmation message\"\"\"\n",
    "\n",
    "    confirmation_message: str = Field(description=\"Natural language confirmation message\")\n",
    "    calendar_link: Optional[str] = Field(description=\"Generated calendar link if applicable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the functions\n",
    "def extract_event_info(user_input: str) -> EventExtraction:\n",
    "    \"\"\"First LLM call to determine if input is a calendar event\"\"\"\n",
    "    logger.info(\"Starting event extraction analysis\")\n",
    "    logger.debug(f\"Input text: {user_input}\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Analyze if the text describes a calendar event.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=EventExtraction,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Extraction complete - Is calendar event: {result.is_calendar_event}, Confidence: {result.confidence_score:.2f}\"\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_event_details(description: str) -> EventDetails:\n",
    "    \"\"\"Second LLM call to extract specific event details\"\"\"\n",
    "    logger.info(\"Starting event details parsing\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Extract detailed event information. When dates reference 'next Tuesday' or similar relative dates, use this current date as reference.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format=EventDetails,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Parsed event details - Name: {result.name}, Date: {result.date}, Duration: {result.duration_minutes}min\"\n",
    "    )\n",
    "    logger.debug(f\"Participants: {', '.join(result.participants)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_confirmation(event_details: EventDetails) -> EventConfirmation:\n",
    "    \"\"\"Third LLM call to generate a confirmation message\"\"\"\n",
    "    logger.info(\"Generating confirmation message\")\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Generate a natural confirmation message for the event. Sign of with your name; Susie\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": str(event_details.model_dump())},\n",
    "        ],\n",
    "        response_format=EventConfirmation,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\"Confirmation message generated successfully\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the functions together\n",
    "def process_calendar_request(user_input: str) -> Optional[EventConfirmation]:\n",
    "    \"\"\"Main function implementing the prompt chain with gate check\"\"\"\n",
    "    logger.info(\"Processing calendar request\")\n",
    "    logger.debug(f\"Raw input: {user_input}\")\n",
    "\n",
    "    # First LLM call: Extract basic info\n",
    "    initial_extraction = extract_event_info(user_input)\n",
    "\n",
    "    # Gate check: Verify if it's a calendar event with sufficient confidence\n",
    "    if (\n",
    "        not initial_extraction.is_calendar_event\n",
    "        or initial_extraction.confidence_score < 0.7\n",
    "    ):\n",
    "        logger.warning(\n",
    "            f\"Gate check failed - is_calendar_event: {initial_extraction.is_calendar_event}, confidence: {initial_extraction.confidence_score:.2f}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    logger.info(\"Gate check passed, proceeding with event processing\")\n",
    "\n",
    "    # Second LLM call: Get detailed event information\n",
    "    event_details = parse_event_details(initial_extraction.description)\n",
    "\n",
    "    # Third LLM call: Generate confirmation\n",
    "    confirmation = generate_confirmation(event_details)\n",
    "\n",
    "    logger.info(\"Calendar request processing completed successfully\")\n",
    "    return confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 16:36:50 - INFO - Processing calendar request\n",
      "2025-03-10 16:36:50 - INFO - Starting event extraction analysis\n",
      "2025-03-10 16:36:52 - INFO - HTTP Request: POST https://aiagenaiinc-oai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-03-10 16:36:52 - INFO - Extraction complete - Is calendar event: True, Confidence: 0.95\n",
      "2025-03-10 16:36:52 - INFO - Gate check passed, proceeding with event processing\n",
      "2025-03-10 16:36:52 - INFO - Starting event details parsing\n",
      "2025-03-10 16:36:53 - INFO - HTTP Request: POST https://aiagenaiinc-oai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-03-10 16:36:53 - INFO - Parsed event details - Name: Team Meeting to Discuss Project Roadmap, Date: 2025-03-18T14:00:00, Duration: 60min\n",
      "2025-03-10 16:36:53 - INFO - Generating confirmation message\n",
      "2025-03-10 16:36:54 - INFO - HTTP Request: POST https://aiagenaiinc-oai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-03-10 16:36:54 - INFO - Confirmation message generated successfully\n",
      "2025-03-10 16:36:54 - INFO - Calendar request processing completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confirmation: Hi Team,\n",
      "\n",
      "This is to confirm our meeting scheduled for March 18, 2025, at 2:00 PM to discuss the project roadmap. It will last for 60 minutes. Looking forward to seeing everyone there!\n",
      "\n",
      "Best,\n",
      "Susie\n"
     ]
    }
   ],
   "source": [
    "# Test the chain with a valid input\n",
    "user_input = \"Let's schedule a 1h team meeting next Tuesday at 2pm with Alice and Bob to discuss the project roadmap.\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"\\nConfirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"This doesn't appear to be a calendar event request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 16:36:54 - INFO - Processing calendar request\n",
      "2025-03-10 16:36:54 - INFO - Starting event extraction analysis\n",
      "2025-03-10 16:36:55 - INFO - HTTP Request: POST https://aiagenaiinc-oai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-03-10 16:36:55 - INFO - Extraction complete - Is calendar event: False, Confidence: 0.90\n",
      "2025-03-10 16:36:55 - WARNING - Gate check failed - is_calendar_event: False, confidence: 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This doesn't appear to be a calendar event request.\n"
     ]
    }
   ],
   "source": [
    "# Test the chain with an invalid input\n",
    "user_input = \"Can you send an email to Alice and Bob to discuss the project roadmap?\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"\\nConfirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"\\nThis doesn't appear to be a calendar event request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
