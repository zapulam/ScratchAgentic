{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI Agents in Pure Python\n",
    "Click this [link](https://www.youtube.com/watch?v=bZzyPscbtI8&t=1116s) to follow along \n",
    "1. Chat completions\n",
    "2. Structured output\n",
    "3. Tool calling\n",
    "4. Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries and env variables\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=os.getenv(\"OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chat completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You're a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a limerick about the Python programming language.\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a land where the coders all cheer,  \n",
      "Python’s syntax is simple and clear.  \n",
      "With libraries vast,  \n",
      "And functions amassed,  \n",
      "It makes programming a pleasure, my dear!  \n"
     ]
    }
   ],
   "source": [
    "# Parse the response\n",
    "response = completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response format in a Pydantic model\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "# Parse the response\n",
    "event = completion.choices[0].message.parsed\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool (function) that we want to call - docs: https://platform.openai.com/docs/guides/function-calling\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model with get_weather tool defined\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\"type\": \"number\"},\n",
    "                    \"longitude\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "system_prompt = \"You are a helpful weather assistant.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"},\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'finish_reason': 'tool_calls',\n",
       "  'index': 0,\n",
       "  'logprobs': None,\n",
       "  'message': {'content': None,\n",
       "   'refusal': None,\n",
       "   'role': 'assistant',\n",
       "   'audio': None,\n",
       "   'function_call': None,\n",
       "   'tool_calls': [{'id': 'call_Atc3R2xGpLlshkwXxt2yJKZ5',\n",
       "     'function': {'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       "      'name': 'get_weather'},\n",
       "     'type': 'function'}]},\n",
       "  'content_filter_results': {}}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model decides to call function(s)\n",
    "completion.model_dump()['choices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute get_weather function\n",
    "def call_function(name, args):\n",
    "    if name == \"get_weather\":\n",
    "        return get_weather(**args)\n",
    "\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    messages.append(completion.choices[0].message)\n",
    "\n",
    "    result = call_function(name, args)\n",
    "    messages.append(\n",
    "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature in Paris is 13.6°C with a wind speed of 6.9 m/s.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supply result and call model again\n",
    "class WeatherResponse(BaseModel):\n",
    "    temperature: float = Field(\n",
    "        description=\"The current temperature in celsius for the given location.\"\n",
    "    )\n",
    "    response: str = Field(\n",
    "        description=\"A natural language response to the user's question.\"\n",
    "    )\n",
    "\n",
    "completion_2 = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "\n",
    "# Check model response\n",
    "final_response = completion_2.choices[0].message.parsed\n",
    "final_response.temperature\n",
    "final_response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the knowledge base retrieval tool - docs: https://platform.openai.com/docs/guides/function-calling\n",
    "def search_kb(question: str):\n",
    "    \"\"\"\n",
    "    Load the whole knowledge base from the JSON file.\n",
    "    (This is a mock function for demonstration purposes, we don't search)\n",
    "    \"\"\"\n",
    "    with open(\"kb.json\", \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model with search_kb tool defined\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_kb\",\n",
    "            \"description\": \"Get the answer to the user's question from the knowledge base.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"question\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"question\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "            \"strict\": True,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "system_prompt = \"You are a helpful assistant that answers questions from the knowledge base about our e-commerce store.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"What is the return policy?\"},\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'finish_reason': 'tool_calls',\n",
       "  'index': 0,\n",
       "  'logprobs': None,\n",
       "  'message': {'content': None,\n",
       "   'refusal': None,\n",
       "   'role': 'assistant',\n",
       "   'audio': None,\n",
       "   'function_call': None,\n",
       "   'tool_calls': [{'id': 'call_KG0ToS9yQQV42KFwAU5AnkHn',\n",
       "     'function': {'arguments': '{\"question\":\"What is the return policy?\"}',\n",
       "      'name': 'search_kb'},\n",
       "     'type': 'function'}]},\n",
       "  'content_filter_results': {}}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model decides to call function(s)\n",
    "completion.model_dump()['choices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute search_kb function\n",
    "def call_function(name, args):\n",
    "    if name == \"search_kb\":\n",
    "        return search_kb(**args)\n",
    "\n",
    "\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    messages.append(completion.choices[0].message)\n",
    "\n",
    "    result = call_function(name, args)\n",
    "    messages.append(\n",
    "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Items can be returned within 30 days of purchase with original receipt. Refunds will be processed to the original payment method within 5-7 business days.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supply result and call model again\n",
    "class KBResponse(BaseModel):\n",
    "    answer: str = Field(description=\"The answer to the user's question.\")\n",
    "    source: int = Field(description=\"The record id of the answer.\")\n",
    "\n",
    "\n",
    "completion_2 = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    response_format=KBResponse,\n",
    ")\n",
    "\n",
    "final_response = completion_2.choices[0].message.parsed\n",
    "final_response.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'finish_reason': 'tool_calls', 'index': 0, 'logprobs': None, 'message': {'content': None, 'refusal': None, 'role': 'assistant', 'audio': None, 'function_call': None, 'tool_calls': [{'id': 'call_xvf6RTT9oJCKxoopxTZzEnKr', 'function': {'arguments': '{\"question\":\"What is the weather in Tokyo?\"}', 'name': 'search_kb'}, 'type': 'function'}]}, 'content_filter_results': {}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to real-time weather information for Tokyo or any location. You may want to check a weather website or app for the most current conditions. If you have other questions related to our e-commerce store, feel free to ask!\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question that doesn't trigger the tool\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather in Tokyo?\"},\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(completion.model_dump()['choices'])\n",
    "\n",
    "for tool_call in completion.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    messages.append(completion.choices[0].message)\n",
    "\n",
    "    result = call_function(name, args)\n",
    "    messages.append(\n",
    "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "    )\n",
    "    \n",
    "completion_2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "completion_2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
